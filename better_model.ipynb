{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80586bb-5545-4eb6-b23c-d04d60c26b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d5a4e4-bb56-4147-8b6d-389d554720cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, sep_type):\n",
    "    \"\"\"Load dataset from file and return dataframe.\"\"\"\n",
    "    return pd.read_csv(filepath, sep=f'{sep_type}', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce3f563-a317-42fa-b1ef-99c6ad6da54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_email(email):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Loại bỏ ký tự không mong muốn\n",
    "    email_cleaned = re.sub('[^a-zA-Z]', ' ', email)\n",
    "    # Chuyển thành chữ thường và tách từ\n",
    "    email_cleaned = email_cleaned.lower().split()\n",
    "    # Lemmatization\n",
    "    email_cleaned = [lemmatizer.lemmatize(word) for word in email_cleaned]\n",
    "    email_cleaned = ' '.join(email_cleaned)\n",
    "    \n",
    "    return email_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97744b7-8776-476f-8812-4614b108ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(words):\n",
    "    \"\"\"Chuyển văn bản thành vector trung bình của Word2Vec (áp dụng cho cả huấn luyện và dự đoán).\"\"\"\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv.index_to_key]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7332a19f-a77f-4c34-9265-74d14959f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(corpus):\n",
    "    words = []\n",
    "    for sent in corpus:\n",
    "        sent_token = sent_tokenize(sent)\n",
    "        for sent in sent_token:\n",
    "            words.append(simple_preprocess(sent))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d85608-ff36-44d9-80cb-9e575971264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(corpus, words):\n",
    "    X = []\n",
    "    for i in range(len(words)):\n",
    "        X.append(avg_word2vec(words[i]))\n",
    "\n",
    "    # Dependent feature\n",
    "    y = messages[list(map(lambda x: len(x) > 0, corpus))]\n",
    "    y = pd.get_dummies(y['label']).astype(int)\n",
    "    y = y.iloc[:, 0].values\n",
    "\n",
    "    df_list = [pd.DataFrame(X[i].reshape(1, -1)) for i in range(len(X))]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    df['Output'] = y\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "    # Independent feature\n",
    "\n",
    "    X = df.drop('Output', axis=1)\n",
    "\n",
    "    y = df['Output']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffe479-39f6-41e3-b9ac-a3c8b61f1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ LOAD NECESSARY DATASET AND MODEL ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7978c3f-a060-4121-a0f2-cad09d0c105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = load_data('SMSSpamCollection.txt', '\\t')\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Data pre-processing\n",
    "corpus = [preprocess_email(text) for text in messages['message']]\n",
    "\n",
    "words = tokenizer(corpus)\n",
    "\n",
    "# CREATE WORD2VEC MODEL\n",
    "model = gensim.models.Word2Vec(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2af75-53bd-4696-aed8-86db8244f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ X Y IMPLEMENT ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657fa21c-f377-48b7-9c6d-3f5f507f54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18742245  0.23839049  0.12214083  0.11458489  0.08225346 -0.47694078\n",
      "  0.16064315  0.46297437 -0.2576366  -0.1325823  -0.14289823 -0.38258544\n",
      " -0.0494565   0.10641685  0.19028778 -0.14978538  0.10438324 -0.30171856\n",
      " -0.00830846 -0.5492333   0.1968523   0.11854635  0.12248059 -0.21289255\n",
      " -0.03403502  0.01122623 -0.2014506  -0.18108334 -0.2372589   0.04153708\n",
      "  0.3093704   0.02310358  0.10164714 -0.16371997 -0.10810269  0.39712524\n",
      "  0.08485963 -0.13236417 -0.1339178  -0.45190564  0.1108321  -0.25132397\n",
      " -0.1891016   0.02107293  0.15716642 -0.01503386 -0.14312    -0.06373135\n",
      "  0.2147276   0.11258324  0.1925603  -0.2073191  -0.05834823  0.06850018\n",
      " -0.1231152   0.0719227   0.1635811  -0.01569516 -0.42661825  0.13437368\n",
      " -0.01297845  0.16048715  0.00496727 -0.09118137 -0.3016874   0.283421\n",
      "  0.07070527  0.23263355 -0.3346211   0.3840157  -0.28539798  0.18525784\n",
      "  0.38782722 -0.10626635  0.3371229   0.05741106  0.09948619 -0.09830821\n",
      " -0.17273721  0.08543866 -0.22726259 -0.11239064 -0.24324436  0.47383747\n",
      " -0.12606364 -0.00871707  0.05388584  0.2326958   0.3355932   0.0948619\n",
      "  0.34473044  0.18442838  0.02870848  0.0579735   0.41771272  0.19752026\n",
      "  0.17492934 -0.18074614  0.14699261  0.02533267]\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation(corpus, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06309f-fecc-4401-b846-21ba27dae8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ TRAINING MODEL ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f043b57a-9855-4fcf-b3fb-ac944cdc07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3073050-c6f8-4c14-bb8b-0a03caea95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ EVALUATE ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8151bb9-faa3-48d1-8a0c-3b23081670c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85c321-81d1-4ec4-8fa7-cda08ac7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bed7d48-edd5-4881-8ca6-6c45222b8b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685816876122083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ea615a-82e0-4789-b0d8-f28ed93eebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       145\n",
      "           1       0.98      0.99      0.98       969\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.94      0.92      0.93      1114\n",
      "weighted avg       0.97      0.97      0.97      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374373b-c984-4433-8603-791b0b12eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ PREDICT ------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0067685f-df2e-479e-98cd-1fe422f246c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'mohan', 'can', 'we', 'get', 'together', 'to', 'watch', 'footbal', 'game', 'tomorrow']\n",
      "Đây là email bình thường (ham).\n",
      "['get', 'rich', 'quick', 'with', 'our', 'investment', 'opportunity', 'join', 'now', 'and', 'start', 'earning', 'big', 'profit']\n",
      "Đây là email spam.\n"
     ]
    }
   ],
   "source": [
    "new_email = \"Hey mohan, can we get together to watch footbal game tomorrow?\"\n",
    "\n",
    "# Bước 1: Xử lý dữ liệu email mới\n",
    "def predict_email(email, classifier):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Loại bỏ ký tự không mong muốn\n",
    "    email_cleaned = re.sub('[^a-zA-Z]', ' ', email)\n",
    "    # Chuyển thành chữ thường và tách từ\n",
    "    email_cleaned = email_cleaned.lower().split()\n",
    "    # Lemmatization\n",
    "    email_cleaned = [lemmatizer.lemmatize(word) for word in email_cleaned]\n",
    "    \n",
    "    print(email_cleaned)\n",
    "\n",
    "    email_vector = avg_word2vec(email_cleaned)\n",
    "    email_vector = email_vector.reshape(1, -1)\n",
    "    predicted_label = classifier.predict(email_vector)\n",
    "\n",
    "    if predicted_label[0] == 0:\n",
    "        print(\"Đây là email spam.\")\n",
    "    else:\n",
    "        print(\"Đây là email bình thường (ham).\")\n",
    "\n",
    "predict_email(new_email, classifier)\n",
    "predict_email('Get rich quick with our investment opportunity! Join now and start earning big profits!', classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df9756e-963b-4853-b3eb-c89b934f4db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'mohan', 'can', 'we', 'get', 'together', 'to', 'watch', 'footbal', 'game', 'tomorrow']\n",
      "Đây là email bình thường (ham).\n",
      "['hi', 'how', 'are', 'you']\n",
      "Đây là email bình thường (ham).\n",
      "['upto', 'discount', 'on', 'parking', 'exclusive', 'offer', 'just', 'for', 'you', 'dont', 'miss', 'this', 'reward']\n",
      "Đây là email bình thường (ham).\n",
      "['i', 'won', 'free', 'vacation', 'you', 'can', 'win', 'click', 'below', 'link']\n",
      "Đây là email spam.\n",
      "['hey', 'sarah', 'are', 'you', 'available', 'for', 'a', 'coffee', 'chat', 'this', 'weekend']\n",
      "Đây là email bình thường (ham).\n",
      "['congratulation', 'you', 've', 'been', 'selected', 'a', 'the', 'winner', 'of', 'a', 'cash', 'prize', 'click', 'the', 'link', 'to', 'claim', 'your', 'reward', 'now', 'claim', 'your', 'exclusive', 'discount', 'code', 'now', 'and', 'save', 'on', 'your', 'next', 'purchase', 'limited', 'time', 'offer']\n",
      "Đây là email spam.\n",
      "['you', 've', 'won', 'a', 'luxury', 'vacation', 'package', 'click', 'the', 'link', 'to', 'claim', 'your', 'prize', 'and', 'enjoy', 'a', 'dream', 'getaway']\n",
      "Đây là email spam.\n",
      "['get', 'rich', 'quick', 'with', 'our', 'investment', 'opportunity', 'join', 'now', 'and', 'start', 'earning', 'big', 'profit']\n",
      "Đây là email spam.\n",
      "['hey', 'there', 'how', 'about', 'catching', 'up', 'for', 'lunch', 'this', 'weekend', 'it', 's', 'been', 'a', 'while', 'since', 'we', 'last', 'met']\n",
      "Đây là email bình thường (ham).\n",
      "['reminder', 'your', 'appointment', 'with', 'the', 'doctor', 'is', 'scheduled', 'for', 'tomorrow', 'at', 'am', 'please', 'remember', 'to', 'bring', 'any', 'necessary', 'document']\n",
      "Đây là email bình thường (ham).\n",
      "['invitation', 'join', 'u', 'for', 'a', 'team', 'building', 'event', 'this', 'friday', 'at', 'the', 'local', 'park', 'food', 'and', 'game', 'provided']\n",
      "Đây là email bình thường (ham).\n"
     ]
    }
   ],
   "source": [
    "emails=[\n",
    "    'Hey mohan, can we get together to watch footbal game tomorrow?',\n",
    "    'hi, how are you?',\n",
    "    'Upto 20% discount on parking, exclusive offer just for you. Dont miss this reward!',\n",
    "    'i won free vacation , you can win click below link',\n",
    "    \"Hey Sarah, are you available for a coffee chat this weekend?\",\n",
    "    \"Congratulations! You've been selected as the winner of a $1000 cash prize. Click the link to claim your reward now!\"\n",
    "    'Claim your exclusive discount code now and save 30% on your next purchase! Limited time offer!',\n",
    "    \"You've won a luxury vacation package! Click the link to claim your prize and enjoy a dream getaway!\",\n",
    "    'Get rich quick with our investment opportunity! Join now and start earning big profits!',\n",
    "    'Hey there, how about catching up for lunch this weekend? It\\'s been a while since we last met!',\n",
    "    'Reminder: Your appointment with the doctor is scheduled for tomorrow at 10 AM. Please remember to bring any necessary documents.',\n",
    "    'Invitation: Join us for a team-building event this Friday at the local park. Food and games provided!',\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "  predict_email(email, classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
